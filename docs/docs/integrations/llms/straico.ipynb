{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Straico\n",
    "\n",
    "Straico is a platform that provides access to a variety of LLMs (including ChatGPT-4, Claude 3 Opus, Llama 3, Gemini, Mixtral, etc)  for text, images and audio generation under one coin-based pricing system.\n",
    "\n",
    "[Official Website](https://straico.com/) \n",
    "\n",
    "[Straico Models and pricing](https://straico.com/multimodel/), or see below\n",
    "\n",
    "This notebook goes over how to use LangChain with Straico for language models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the Environment API Key\n",
    "Make sure to get your API key from Straico. You have to [Login](https://platform.straico.com/) and get your token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "from getpass import getpass\n",
    "\n",
    "STRAICO_API_TOKEN = getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"STRAICO_API_TOKEN\"] = STRAICO_API_TOKEN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use ChatStraico to call an LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'ChatStraico' from 'langchain_community.chat_models' (/Users/lilly/code/langchain/.venv/lib/python3.12/site-packages/langchain_community/chat_models/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_community\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchat_models\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ChatStraico\n\u001b[1;32m      3\u001b[0m llm \u001b[38;5;241m=\u001b[39m ChatStraico(model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mopenai/gpt-4-0125-preview\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m llm\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'ChatStraico' from 'langchain_community.chat_models' (/Users/lilly/code/langchain/.venv/lib/python3.12/site-packages/langchain_community/chat_models/__init__.py)"
     ]
    }
   ],
   "source": [
    "from langchain_community.chat_models import ChatStraico\n",
    "\n",
    "llm = ChatStraico(model=\"openai/gpt-4-0125-preview\")\n",
    "llm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call generate() to get the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '.venv (Python 3.12.3)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/Users/lilly/code/langchain/.venv/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "message = HumanMessage(content=\"Hello\")\n",
    "\n",
    "llm.generate(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Prompt Template\n",
    "We will create a prompt template to help to define the prompt for the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ChatStraico' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprompts\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ChatPromptTemplate\n\u001b[0;32m----> 3\u001b[0m chat \u001b[38;5;241m=\u001b[39m \u001b[43mChatStraico\u001b[49m(model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mopenai/gpt-3.5-turbo-0125\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m template \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124m Either say \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfoobar\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or answer to my input: \u001b[39m\u001b[38;5;132;01m{input}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m      6\u001b[0m system \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are a helpful assistant.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ChatStraico' is not defined"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    " \n",
    "chat = ChatStraico(model=\"openai/gpt-3.5-turbo-0125\")\n",
    "\n",
    "template = \"\"\" Either say 'foobar' or answer to my input: {input} \"\"\"\n",
    "system = \"You are a helpful assistant.\"\n",
    "prompt = ChatPromptTemplate.from_messages([(\"system\", system), (\"human\", template)])\n",
    "chain = prompt | chat\n",
    "response = chain.invoke(\n",
    "    {\n",
    "        \"input\": \"Hello\"\n",
    "    }\n",
    ")\n",
    "response.content\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview of models and prices "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '.venv (Python 3.12.3)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/Users/lilly/code/langchain/.venv/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "{\n",
    "    \"name\": \"Anthropic: Claude 3 Haiku\",\n",
    "    \"model\": \"anthropic/claude-3-haiku:beta\",\n",
    "    \"pricing\": {\"coins\": 1, \"words\": 100},\n",
    "}, {\n",
    "    \"name\": \"Anthropic: Claude 3 Opus\",\n",
    "    \"model\": \"anthropic/claude-3-opus\",\n",
    "    \"pricing\": {\"coins\": 24, \"words\": 100},\n",
    "}, {\n",
    "    \"name\": \"Anthropic: Claude 3 Sonnet\",\n",
    "    \"model\": \"anthropic/claude-3-sonnet\",\n",
    "    \"pricing\": {\"coins\": 5, \"words\": 100},\n",
    "}, {\n",
    "    \"name\": \"Anthropic: Claude 3.5 Sonnet\",\n",
    "    \"model\": \"anthropic/claude-3.5-sonnet\",\n",
    "    \"pricing\": {\"coins\": 5, \"words\": 100},\n",
    "}, {\n",
    "    \"name\": \"Anthropic: Claude v2.1\",\n",
    "    \"model\": \"anthropic/claude-2\",\n",
    "    \"pricing\": {\"coins\": 8, \"words\": 100},\n",
    "}, {\n",
    "    \"name\": \"Cohere: Command R+\",\n",
    "    \"model\": \"cohere/command-r-plus\",\n",
    "    \"pricing\": {\"coins\": 4, \"words\": 100},\n",
    "}, {\n",
    "    \"name\": \"Dolphin 2.6 Mixtral 8x7B\",\n",
    "    \"model\": \"cognitivecomputations/dolphin-mixtral-8x7b\",\n",
    "    \"pricing\": {\"coins\": 1, \"words\": 100},\n",
    "}, {\n",
    "    \"name\": \"Goliath 120B\",\n",
    "    \"model\": \"alpindale/goliath-120b\",\n",
    "    \"pricing\": {\"coins\": 5, \"words\": 100},\n",
    "}, {\n",
    "    \"name\": \"Google: Gemini Pro (preview)\",\n",
    "    \"model\": \"google/gemini-pro\",\n",
    "    \"pricing\": {\"coins\": 1, \"words\": 100},\n",
    "}, {\n",
    "    \"name\": \"Google: Gemini Pro 1.5 (preview)\",\n",
    "    \"model\": \"google/gemini-pro-1.5\",\n",
    "    \"pricing\": {\"coins\": 3, \"words\": 100},\n",
    "}, {\n",
    "    \"name\": \"Google: Gemma 7B\",\n",
    "    \"model\": \"google/gemma-7b-it\",\n",
    "    \"pricing\": {\"coins\": 1, \"words\": 100},\n",
    "}, {\n",
    "    \"name\": \"Google: PaLM 2 Chat 32k\",\n",
    "    \"model\": \"google/palm-2-chat-bison-32k\",\n",
    "    \"pricing\": {\"coins\": 1, \"words\": 100},\n",
    "}, {\n",
    "    \"name\": \"Gryphe: MythoMax L2 13B 8k (beta)\",\n",
    "    \"model\": \"gryphe/mythomax-l2-13b-8k\",\n",
    "    \"pricing\": {\"coins\": 1, \"words\": 100},\n",
    "}, {\n",
    "    \"name\": \"Meta: Llama 3 70B Instruct (nitro)\",\n",
    "    \"model\": \"meta-llama/llama-3-70b-instruct:nitro\",\n",
    "    \"pricing\": {\"coins\": 1, \"words\": 100},\n",
    "}, {\n",
    "    \"name\": \"Meta: Llama 3 8B Instruct\",\n",
    "    \"model\": \"meta-llama/llama-3-8b-instruct\",\n",
    "    \"pricing\": {\"coins\": 0.5, \"words\": 100},\n",
    "}, {\n",
    "    \"name\": \"Mistral: Large\",\n",
    "    \"model\": \"mistralai/mistral-large\",\n",
    "    \"pricing\": {\"coins\": 8, \"words\": 100},\n",
    "}, {\n",
    "    \"name\": \"Mistral: Mixtral 8x7B (beta)\",\n",
    "    \"model\": \"mistralai/mixtral-8x7b-instruct\",\n",
    "    \"pricing\": {\"coins\": 1, \"words\": 100},\n",
    "}, {\n",
    "    \"name\": \"OpenAI: GPT-3.5 Turbo 16k\",\n",
    "    \"model\": \"openai/gpt-3.5-turbo-0125\",\n",
    "    \"pricing\": {\"coins\": 1, \"words\": 100},\n",
    "}, {\n",
    "    \"name\": \"OpenAI: GPT-4\",\n",
    "    \"model\": \"openai/gpt-4\",\n",
    "    \"pricing\": {\"coins\": 20, \"words\": 100},\n",
    "}, {\n",
    "    \"name\": \"OpenAI: GPT-4 Turbo 128k - New (April 9)\",\n",
    "    \"model\": \"openai/gpt-4-turbo-2024-04-09\",\n",
    "    \"pricing\": {\"coins\": 8, \"words\": 100},\n",
    "}, {\n",
    "    \"name\": \"OpenAI: GPT-4 Turbo 128k - Old\",\n",
    "    \"model\": \"openai/gpt-4-0125-preview\",\n",
    "    \"pricing\": {\"coins\": 8, \"words\": 100},\n",
    "}, {\n",
    "    \"name\": \"OpenAI: GPT-4 Vision\",\n",
    "    \"model\": \"openai/gpt-4-vision-preview\",\n",
    "    \"pricing\": {\"coins\": 10, \"words\": 100},\n",
    "}, {\n",
    "    \"name\": \"OpenAI: GPT-4o\",\n",
    "    \"model\": \"openai/gpt-4o\",\n",
    "    \"pricing\": {\"coins\": 4, \"words\": 100},\n",
    "}, {\n",
    "    \"name\": \"Perplexity: Llama3 Sonar 8B Online\",\n",
    "    \"model\": \"perplexity/llama-3-sonar-small-32k-online\",\n",
    "    \"pricing\": {\"coins\": 1, \"words\": 100},\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "a0a0263b650d907a3bfe41c0f8d6a63a071b884df3cfdc1579f00cdc1aed6b03"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
